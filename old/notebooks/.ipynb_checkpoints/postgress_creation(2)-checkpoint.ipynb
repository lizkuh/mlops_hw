{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59d0e5a",
   "metadata": {},
   "source": [
    "### Установить зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21592c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install psycopg2\n",
    "# !conda install sqlalchemy\n",
    "# !pip install sqlalchemy-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0d2e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# conda install sqlalchemy\n",
    "# import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe0890",
   "metadata": {},
   "source": [
    "## Создать базу данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51e1636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:password@172.19.0.2/temp')\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665101c",
   "metadata": {},
   "source": [
    "#### Посмотреть список всех баз данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17305c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('postgres',), ('temp',), ('tutorial',)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Connect to PostgreSQL DBMS\n",
    "# con = psycopg2.connect(\"user=PGUSER password='password'\");\n",
    "\n",
    "\n",
    "\n",
    "def execute(q = \"\"\"SELECT datname FROM pg_database WHERE datistemplate = false;\"\"\"):\n",
    "    conn=psycopg2.connect(#database=\"mydb\",\n",
    "                          user=\"postgres\",\n",
    "                          host=\"172.19.0.2\",\n",
    "                          port='5432',\n",
    "                          password=\"password\"\n",
    "                        )\n",
    "    \n",
    "    cursor          = conn.cursor();\n",
    "    cursor.execute(q)\n",
    "    res = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return res\n",
    "\n",
    "execute()\n",
    "# cursor.execute('create database testdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee32634",
   "metadata": {},
   "source": [
    "#### Тест создания базы их ORM\n",
    "\n",
    "https://docs.sqlalchemy.org/en/14/orm/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b5290a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:password@172.19.0.2/tutorial\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:password@172.19.0.2/tutorial')\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8223a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import declarative_base\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07242a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String\n",
    "class User0(Base):\n",
    "    __tablename__ = \"users0\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String)\n",
    "    fullname = Column(String)\n",
    "    nickname = Column(String)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<User(name='%s', fullname='%s', nickname='%s')>\" % (\n",
    "            self.name,\n",
    "            self.fullname,\n",
    "            self.nickname,\n",
    "        )\n",
    "    \n",
    "    def xyu(self):\n",
    "        return '123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d9611b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('users', MetaData(), Column('id', Integer(), table=<users>, primary_key=True, nullable=False), Column('name', String(), table=<users>), Column('fullname', String(), table=<users>), Column('nickname', String(), table=<users>), schema=None)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User.__table__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "07c9e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d0588881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column(None, Integer(), table=None, primary_key=True, nullable=False, default=Sequence('user_id_seq'))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import Sequence\n",
    "\n",
    "Column(Integer, Sequence(\"user_id_seq\"), primary_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9f96f38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<User(name='ed', fullname='Ed Jones', nickname='edsnickname')>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "ed_user = User(name=\"ed\", fullname=\"Ed Jones\", nickname=\"edsnickname\")\n",
    "session.add(ed_user)\n",
    "\n",
    "our_user = (session.query(User).filter_by(name=\"ed\").first()) \n",
    "our_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "15be886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dade2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_all(\n",
    "     [\n",
    "         User(name=\"wendy\", fullname=\"Wendy Williams\", nickname=\"windy\"),\n",
    "         User(name=\"mary\", fullname=\"Mary Contrary\", nickname=\"mary\"),\n",
    "         User(name=\"fred\", fullname=\"Fred Flintstone\", nickname=\"freddy\"),\n",
    "     ]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cfcf8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "70bc4c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute(q):\n",
    "    conn=psycopg2.connect(database=\"tutorial\",\n",
    "                          user=\"postgres\",\n",
    "                          host=\"172.19.0.2\",\n",
    "                          port='5432',\n",
    "                          password=\"password\"\n",
    "                        )\n",
    "    \n",
    "    cursor          = conn.cursor();\n",
    "    cursor.execute(q)\n",
    "    res = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return res\n",
    "\n",
    "execute(\"select * from users0;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8de826",
   "metadata": {},
   "source": [
    "#### Посмотреть глазами на таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a8fd68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>ed</td>\n",
       "      <td>Ed Jones</td>\n",
       "      <td>edsnickname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>wendy</td>\n",
       "      <td>Wendy Williams</td>\n",
       "      <td>windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>mary</td>\n",
       "      <td>Mary Contrary</td>\n",
       "      <td>mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>fred</td>\n",
       "      <td>Fred Flintstone</td>\n",
       "      <td>freddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>wendy</td>\n",
       "      <td>Wendy Williams</td>\n",
       "      <td>windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>mary</td>\n",
       "      <td>Mary Contrary</td>\n",
       "      <td>mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>fred</td>\n",
       "      <td>Fred Flintstone</td>\n",
       "      <td>freddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>wendy</td>\n",
       "      <td>Wendy Williams</td>\n",
       "      <td>windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>mary</td>\n",
       "      <td>Mary Contrary</td>\n",
       "      <td>mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>fred</td>\n",
       "      <td>Fred Flintstone</td>\n",
       "      <td>freddy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1                2            3\n",
       "0   3     ed         Ed Jones  edsnickname\n",
       "1   4  wendy   Wendy Williams        windy\n",
       "2   5   mary    Mary Contrary         mary\n",
       "3   6   fred  Fred Flintstone       freddy\n",
       "4   7  wendy   Wendy Williams        windy\n",
       "5   8   mary    Mary Contrary         mary\n",
       "6   9   fred  Fred Flintstone       freddy\n",
       "7  10  wendy   Wendy Williams        windy\n",
       "8  11   mary    Mary Contrary         mary\n",
       "9  12   fred  Fred Flintstone       freddy"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(execute())\n",
    "\n",
    "# execute(\"SELECT table_name FROM information_schema. tables WHERE table_type='BASE TABLE' AND table_schema='public'\")\n",
    "# \n",
    "# execute(\"describe users\")\n",
    "# import pandas as pd\n",
    "pd.DataFrame(execute(\"SELECT * FROM users;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ae883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c250bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "98c20513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss : {'deviance', 'exponential'}, default='deviance'\n",
    "#     The loss function to be optimized. 'deviance' refers to\n",
    "#     deviance (= logistic regression) for classification\n",
    "#     with probabilistic outputs. For loss 'exponential' gradient\n",
    "#     boosting recovers the AdaBoost algorithm.\n",
    "\n",
    "# learning_rate : float, default=0.1\n",
    "#     Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
    "#     There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "# n_estimators : int, default=100\n",
    "#     The number of boosting stages to perform. Gradient boosting\n",
    "#     is fairly robust to over-fitting so a large number usually\n",
    "#     results in better performance.\n",
    "\n",
    "# subsample : float, default=1.0\n",
    "#     The fraction of samples to be used for fitting the individual base\n",
    "#     learners. If smaller than 1.0 this results in Stochastic Gradient\n",
    "#     Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
    "#     Choosing `subsample < 1.0` leads to a reduction of variance\n",
    "#     and an increase in bias.\n",
    "\n",
    "# criterion : {'friedman_mse', 'squared_error', 'mse', 'mae'},             default='friedman_mse'\n",
    "#     The function to measure the quality of a split. Supported criteria\n",
    "#     are 'friedman_mse' for the mean squared error with improvement\n",
    "#     score by Friedman, 'squared_error' for mean squared error, and 'mae'\n",
    "#     for the mean absolute error. The default value of 'friedman_mse' is\n",
    "#     generally the best as it can provide a better approximation in some\n",
    "#     cases.\n",
    "\n",
    "#     .. versionadded:: 0.18\n",
    "\n",
    "#     .. deprecated:: 0.24\n",
    "#         `criterion='mae'` is deprecated and will be removed in version\n",
    "#         1.1 (renaming of 0.26). Use `criterion='friedman_mse'` or\n",
    "#         `'squared_error'` instead, as trees should use a squared error\n",
    "#         criterion in Gradient Boosting.\n",
    "\n",
    "#     .. deprecated:: 1.0\n",
    "#         Criterion 'mse' was deprecated in v1.0 and will be removed in\n",
    "#         version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
    "\n",
    "# min_samples_split : int or float, default=2\n",
    "#     The minimum number of samples required to split an internal node:\n",
    "\n",
    "#     - If int, then consider `min_samples_split` as the minimum number.\n",
    "#     - If float, then `min_samples_split` is a fraction and\n",
    "#       `ceil(min_samples_split * n_samples)` are the minimum\n",
    "#       number of samples for each split.\n",
    "\n",
    "#     .. versionchanged:: 0.18\n",
    "#        Added float values for fractions.\n",
    "\n",
    "# min_samples_leaf : int or float, default=1\n",
    "#     The minimum number of samples required to be at a leaf node.\n",
    "#     A split point at any depth will only be considered if it leaves at\n",
    "#     least ``min_samples_leaf`` training samples in each of the left and\n",
    "#     right branches.  This may have the effect of smoothing the model,\n",
    "#     especially in regression.\n",
    "\n",
    "#     - If int, then consider `min_samples_leaf` as the minimum number.\n",
    "#     - If float, then `min_samples_leaf` is a fraction and\n",
    "#       `ceil(min_samples_leaf * n_samples)` are the minimum\n",
    "#       number of samples for each node.\n",
    "\n",
    "#     .. versionchanged:: 0.18\n",
    "#        Added float values for fractions.\n",
    "\n",
    "# min_weight_fraction_leaf : float, default=0.0\n",
    "#     The minimum weighted fraction of the sum total of weights (of all\n",
    "#     the input samples) required to be at a leaf node. Samples have\n",
    "#     equal weight when sample_weight is not provided.\n",
    "\n",
    "# max_depth : int, default=3\n",
    "#     The maximum depth of the individual regression estimators. The maximum\n",
    "#     depth limits the number of nodes in the tree. Tune this parameter\n",
    "#     for best performance; the best value depends on the interaction\n",
    "#     of the input variables.\n",
    "\n",
    "# min_impurity_decrease : float, default=0.0\n",
    "#     A node will be split if this split induces a decrease of the impurity\n",
    "#     greater than or equal to this value.\n",
    "\n",
    "#     The weighted impurity decrease equation is the following::\n",
    "\n",
    "#         N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
    "#                             - N_t_L / N_t * left_impurity)\n",
    "\n",
    "#     where ``N`` is the total number of samples, ``N_t`` is the number of\n",
    "#     samples at the current node, ``N_t_L`` is the number of samples in the\n",
    "#     left child, and ``N_t_R`` is the number of samples in the right child.\n",
    "\n",
    "#     ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
    "#     if ``sample_weight`` is passed.\n",
    "\n",
    "#     .. versionadded:: 0.19\n",
    "\n",
    "# init : estimator or 'zero', default=None\n",
    "#     An estimator object that is used to compute the initial predictions.\n",
    "#     ``init`` has to provide :meth:`fit` and :meth:`predict_proba`. If\n",
    "#     'zero', the initial raw predictions are set to zero. By default, a\n",
    "#     ``DummyEstimator`` predicting the classes priors is used.\n",
    "\n",
    "# random_state : int, RandomState instance or None, default=None\n",
    "#     Controls the random seed given to each Tree estimator at each\n",
    "#     boosting iteration.\n",
    "#     In addition, it controls the random permutation of the features at\n",
    "#     each split (see Notes for more details).\n",
    "#     It also controls the random splitting of the training data to obtain a\n",
    "#     validation set if `n_iter_no_change` is not None.\n",
    "#     Pass an int for reproducible output across multiple function calls.\n",
    "#     See :term:`Glossary <random_state>`.\n",
    "\n",
    "# max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None\n",
    "#     The number of features to consider when looking for the best split:\n",
    "\n",
    "#     - If int, then consider `max_features` features at each split.\n",
    "#     - If float, then `max_features` is a fraction and\n",
    "#       `int(max_features * n_features)` features are considered at each\n",
    "#       split.\n",
    "#     - If 'auto', then `max_features=sqrt(n_features)`.\n",
    "#     - If 'sqrt', then `max_features=sqrt(n_features)`.\n",
    "#     - If 'log2', then `max_features=log2(n_features)`.\n",
    "#     - If None, then `max_features=n_features`.\n",
    "\n",
    "#     Choosing `max_features < n_features` leads to a reduction of variance\n",
    "#     and an increase in bias.\n",
    "\n",
    "#     Note: the search for a split does not stop until at least one\n",
    "#     valid partition of the node samples is found, even if it requires to\n",
    "#     effectively inspect more than ``max_features`` features.\n",
    "\n",
    "# verbose : int, default=0\n",
    "#     Enable verbose output. If 1 then it prints progress and performance\n",
    "#     once in a while (the more trees the lower the frequency). If greater\n",
    "#     than 1 then it prints progress and performance for every tree.\n",
    "\n",
    "# max_leaf_nodes : int, default=None\n",
    "#     Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
    "#     Best nodes are defined as relative reduction in impurity.\n",
    "#     If None then unlimited number of leaf nodes.\n",
    "\n",
    "# warm_start : bool, default=False\n",
    "#     When set to ``True``, reuse the solution of the previous call to fit\n",
    "#     and add more estimators to the ensemble, otherwise, just erase the\n",
    "#     previous solution. See :term:`the Glossary <warm_start>`.\n",
    "\n",
    "# validation_fraction : float, default=0.1\n",
    "#     The proportion of training data to set aside as validation set for\n",
    "#     early stopping. Must be between 0 and 1.\n",
    "#     Only used if ``n_iter_no_change`` is set to an integer.\n",
    "\n",
    "#     .. versionadded:: 0.20\n",
    "\n",
    "# n_iter_no_change : int, default=None\n",
    "#     ``n_iter_no_change`` is used to decide if early stopping will be used\n",
    "#     to terminate training when validation score is not improving. By\n",
    "#     default it is set to None to disable early stopping. If set to a\n",
    "#     number, it will set aside ``validation_fraction`` size of the training\n",
    "#     data as validation and terminate training when validation score is not\n",
    "#     improving in all of the previous ``n_iter_no_change`` numbers of\n",
    "#     iterations. The split is stratified.\n",
    "\n",
    "#     .. versionadded:: 0.20\n",
    "\n",
    "# tol : float, default=1e-4\n",
    "#     Tolerance for the early stopping. When the loss is not improving\n",
    "#     by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
    "#     number), the training stops.\n",
    "\n",
    "#     .. versionadded:: 0.20\n",
    "\n",
    "# ccp_alpha : non-negative float, default=0.0\n",
    "#     Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
    "#     subtree with the largest cost complexity that is smaller than\n",
    "#     ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
    "#     :ref:`minimal_cost_complexity_pruning` for details.\n",
    "\n",
    "#     .. versionadded:: 0.22\n",
    "\n",
    "# Attributes\n",
    "# ----------\n",
    "# n_estimators_ : int\n",
    "#     The number of estimators as selected by early stopping (if\n",
    "#     ``n_iter_no_change`` is specified). Otherwise it is set to\n",
    "#     ``n_estimators``.\n",
    "\n",
    "#     .. versionadded:: 0.20\n",
    "\n",
    "# feature_importances_ : ndarray of shape (n_features,)\n",
    "#     The impurity-based feature importances.\n",
    "#     The higher, the more important the feature.\n",
    "#     The importance of a feature is computed as the (normalized)\n",
    "#     total reduction of the criterion brought by that feature.  It is also\n",
    "#     known as the Gini importance.\n",
    "\n",
    "#     Warning: impurity-based feature importances can be misleading for\n",
    "#     high cardinality features (many unique values). See\n",
    "#     :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
    "\n",
    "# oob_improvement_ : ndarray of shape (n_estimators,)\n",
    "#     The improvement in loss (= deviance) on the out-of-bag samples\n",
    "#     relative to the previous iteration.\n",
    "#     ``oob_improvement_[0]`` is the improvement in\n",
    "#     loss of the first stage over the ``init`` estimator.\n",
    "#     Only available if ``subsample < 1.0``\n",
    "\n",
    "# train_score_ : ndarray of shape (n_estimators,)\n",
    "#     The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
    "#     model at iteration ``i`` on the in-bag sample.\n",
    "#     If ``subsample == 1`` this is the deviance on the training data.\n",
    "\n",
    "# loss_ : LossFunction\n",
    "#     The concrete ``LossFunction`` object.\n",
    "\n",
    "# init_ : estimator\n",
    "#     The estimator that provides the initial predictions.\n",
    "#     Set via the ``init`` argument or ``loss.init_estimator``.\n",
    "\n",
    "# estimators_ : ndarray of DecisionTreeRegressor of             shape (n_estimators, ``loss_.K``)\n",
    "#     The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
    "#     classification, otherwise n_classes.\n",
    "\n",
    "# classes_ : ndarray of shape (n_classes,)\n",
    "#     The classes labels.\n",
    "\n",
    "# n_features_ : int\n",
    "#     The number of data features.\n",
    "\n",
    "#     .. deprecated:: 1.0\n",
    "#         Attribute `n_features_` was deprecated in version 1.0 and will be\n",
    "#         removed in 1.2. Use `n_features_in_` instead.\n",
    "\n",
    "# n_features_in_ : int\n",
    "#     Number of features seen during :term:`fit`.\n",
    "\n",
    "#     .. versionadded:: 0.24\n",
    "\n",
    "# feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
    "#     Names of features seen during :term:`fit`. Defined only when `X`\n",
    "#     has feature names that are all strings.\n",
    "\n",
    "#     .. versionadded:: 1.0\n",
    "\n",
    "# n_classes_ : int\n",
    "#     The number of classes.\n",
    "\n",
    "# max_features_ : int\n",
    "#     The inferred value of max_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7d89a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=49)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier(n_estimators = 100, \n",
    "#                        max_depth = 5,\n",
    "#                        random_state = 49,\n",
    "#                        min_samples_leaf = 9\n",
    "#                       )\n",
    "\n",
    "GradientBoostingClassifier(n_estimators = 100, \n",
    "                       max_depth = 5,\n",
    "                       random_state = 49,\n",
    "                       min_samples_leaf = 9\n",
    "                      )\n",
    "\n",
    "LogisticRegression(penalty = 'l2',\n",
    "                   C = 10.0,\n",
    "                   random_state = 49,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c436f79b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Subscripted generics cannot be used with class and instance checks",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4852/2501584891.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"123\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/typing.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/typing.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         raise TypeError(\"Subscripted generics cannot be used with\"\n\u001b[0m\u001b[1;32m    724\u001b[0m                         \" class and instance checks\")\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Subscripted generics cannot be used with class and instance checks"
     ]
    }
   ],
   "source": [
    "isinstance(\"123\", Union[str, int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4fa03d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydoc import locate\n",
    "isinstance(1.0, locate('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fef89545",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4852/2493558602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"123\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "isinstance(\"123\", \"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5e9c80ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'RandomForestClassifier',\n",
       "  'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'},\n",
       " {'model_type': 'LogisticRegression',\n",
       "  'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'},\n",
       " {'model_type': 'GradientBoostingClassifier',\n",
       "  'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'}]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Union\n",
    "import json\n",
    "possible_models = [{\"model_type\": \"RandomForestClassifier\",\n",
    "                    \"fit_params_json\": json.dumps({\"n_estimators\": \"int\",\n",
    "                                        \"max_depth\": \"int\",\n",
    "                                        \"random_state\": \"int\",\n",
    "                                        \"min_samples_leaf\": \"int\",\n",
    "                                        \"learning_rate\": \"float\"\n",
    "                                       })\n",
    "                   },\n",
    "                   {\"model_type\": \"LogisticRegression\",\n",
    "                    \"fit_params_json\": json.dumps({\"n_estimators\": \"int\",\n",
    "                                        \"max_depth\": \"int\",\n",
    "                                        \"random_state\": \"int\",\n",
    "                                        \"min_samples_leaf\": \"int\",\n",
    "                                        \"learning_rate\": \"float\"\n",
    "                                       })\n",
    "                   },\n",
    "                   {\"model_type\": \"GradientBoostingClassifier\",\n",
    "                   \"fit_params_json\": json.dumps({\"penalty\": \"str\",\n",
    "                                       \"max_depth\": \"int\",\n",
    "                                       \"random_state\": \"int\",\n",
    "                                       \"min_samples_leaf\": \"int\"\n",
    "                                       })\n",
    "                   }\n",
    "                  ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ff36b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected object or value\n"
     ]
    },
    {
     "ename": "WrongInputData",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4852/3538568874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1133\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWrongInputData\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4852/3538568874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWrongInputData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mWrongInputData\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "class WrongInputData(Exception):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    pd.read_json(\"\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    raise WrongInputData(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f13635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dc071c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('O')], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('[{\"123.js\":0.0}, {\"123.js\": \"\"}]').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd289188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan\n",
    "1) Rewrite code of microservice (1 hour)\n",
    "   -[20 min] start with get_model_types\n",
    "    \n",
    "   -[30 min] Add ORM\n",
    "     - model.models_signatures\n",
    "     - model.model_fitted\n",
    "     \n",
    "   -[1 h] Normal code\n",
    "   - Docstring everywhere\n",
    "   - Only 5 Api methods\n",
    "   - 3 files\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "001f0048",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2619501420.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4852/2619501420.py\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    data =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "#exceptions.py\n",
    "class WrongInputData(Exception):\n",
    "    \"\"\"\n",
    "        Error at input_data_json\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# utils.py\n",
    "def __json_to_dataframe(json_input):\n",
    "    \"\"\"\n",
    "        Change input json to \n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_json(json_input)\n",
    "        #ToDo: Check that types are not objects or string\n",
    "        # These will cause error with hight probability\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise WrongInputData(e)\n",
    "\n",
    "        \n",
    "def __create_model(model_type: str, fit_params_json: str) -> None:\n",
    "    \n",
    "    \n",
    "def fit_model(model_name: str, fit_params_json: str, input_data_json: str) -> None:\n",
    "    \"\"\"\n",
    "        fit model\n",
    "    \"\"\"\n",
    "    data  = __json_to_dataframe(input_data_json)\n",
    "    model = __create_model(model_type, fit_params_json)\n",
    "    __fit_model(model, data)\n",
    "    write_model_to_db()\n",
    "    pass\n",
    "\n",
    "def get_model_types() -> Dict[str, Any]:\n",
    "    pass\n",
    "\n",
    "def predict_model(model_id: str, input_data_json: str) -> Dict[str, Any]:\n",
    "    pass\n",
    "\n",
    "def delete_mode(model_id: str) -> Any:\n",
    "    pass\n",
    "\n",
    "def refit_model(model_id: str, input_data_json: str) -> None:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8f3bb",
   "metadata": {},
   "source": [
    "Что нужно делать\n",
    "- fastapi микросервис со следующими функциями (2 часа)\n",
    "  - fit_model(model_name, params, input_data)\n",
    "   \n",
    "  - get_model_types() -> json of types\n",
    "  \n",
    "  - predict_model(model_id, input_data) -> output_data\n",
    "  \n",
    "  - delete_model(model_id)\n",
    "  \n",
    "  - refit_model(model_id, input_data)\n",
    "  \n",
    "В базе postgress лежит (2 часа)\n",
    "models\n",
    "model_type: str;model_name: str;model_id: str;fit_params: str(json);(path_to_model??);bin_pickle???\n",
    "\n",
    "\n",
    "model_types\n",
    "model_type;possible_params\n",
    "           (param, type)\n",
    "\n",
    "\n",
    "model_type | model_name | params_fit\n",
    "\n",
    "\n",
    "Два docker-а один для базы один для микросервиса и общая сетка для них (1 час)\n",
    "Все оформлено в docker compose\n",
    "\n",
    "unit тесты на проверку каждого из методов (1 час)\n",
    "\n",
    "\n",
    "CI pipeline + dockerhub - Женя (2 часа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "Дз 1 (12)\n",
    "Реализовать API (REST либо процедуры gRPC), которое умеет:\n",
    "1. Обучать ML-модель с возможностью настройки\n",
    "гиперпараметров. При этом гиперпараметры для разных\n",
    "моделей могут быть разные. Минимальное количество классов\n",
    "моделей доступных для обучения == 2.\n",
    "2. Возвращать список доступных для обучения классов моделей\n",
    "3. Возвращать предсказание конкретной модели (как следствие,\n",
    "система должна уметь хранить несколько обученных моделей)\n",
    "4. Обучать заново и удалять уже обученные модели\n",
    "\n",
    "Оценка\n",
    "• [4 балла] Работоспособность программы - то что ее можно запустить и\n",
    "она выполняет задачи, перечисленные в требованиях.\n",
    "• [3 балла] Корректность и адекватность программы - корректная\n",
    "обработка ошибок, адекватный выбор структур классов, понятная\n",
    "документация (docstring-и адекатные здесь обязательны)\n",
    "• [2 балла] Стиль кода - соблюдение стайлгайда. Буду проверять flake8\n",
    "(не все ошибки на самом деле являются таковыми, но какие можно\n",
    "оставить – решать вам, насколько они критичны, списка нет )\n",
    "• [1 балл] Swagger – Есть документация API (Swagger) с помощью flask-\n",
    "restx или аналога\n",
    "• [2 балла] – Реализация и REST API, и gRPC\n",
    "\n",
    "Дз 2 (11)\n",
    "К приложению из первого дз нужно добавить:\n",
    "1. Работу с базой данной Postgresql.\n",
    "2. Сборку самого вашего микросервиса в docker образ (образ\n",
    "нужно запушить в docker hub)\n",
    "3. Запуск вашего сервиса и БД через docker-compose\n",
    "4. [полуопционально] Запуск вашего сервиса в кубере\n",
    "5. [на будущее] Написать тесты\n",
    "\n",
    "Оценка\n",
    "• [3 балла] В приложение добавлена работа с БД\n",
    "• [3 балла] Получившееся приложение собрано в Docker-образ и он\n",
    "опубликован в DockerHub\n",
    "• [3 балла] Приложение можно запустить утилитой docker-compose\n",
    "• [2 балла] Приложение запускается на Kubernetes (требуется\n",
    "приложить скрипт поднятия кластера minikube и деплоймент,\n",
    "либо Mak\n",
    "\n",
    "Дз 3 ()\n",
    "К приложению из второго дз нужно добавить:\n",
    "1. Unit тесты. Работу с БД/S3 замокать\n",
    "2. CI пайплайн:\n",
    "1. Запуск тестов\n",
    "2. Сборка образа и пуш ее в докерхаб\n",
    "\n",
    "Оценка\n",
    "• [10 баллов] Есть тесты, они достаточно полные.\n",
    "• [5 баллов] Есть CI Pipeline, который запускается при Merge\n",
    "Request-ах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba09ddd",
   "metadata": {},
   "source": [
    "### Проектирование баз\n",
    "1) model_params - все типы моделей и json конфиги к ним\n",
    "model_type | json_config\n",
    "\n",
    "2) models \n",
    "model_name | model_id | model_type | fit_params | fn_train | fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5298471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "# # engine = create_engine('postgresql+psycopg2://user:password@hostname/database_name')\n",
    "# engine = create_engine('postgresql+psycopg2://postgres:passwordz@172.19.0.2/test')\n",
    "# create_database(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "327ec0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4bc6e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('postgres',), ('temp',)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ecf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76946944",
   "metadata": {},
   "outputs": [
    {
     "ename": "ActiveSqlTransaction",
     "evalue": "CREATE DATABASE cannot run inside a transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActiveSqlTransaction\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20/2720702755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"create database testdb;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_20/151184544.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"SELECT datname FROM pg_database WHERE datistemplate = false;\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcursor\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActiveSqlTransaction\u001b[0m: CREATE DATABASE cannot run inside a transaction block\n"
     ]
    }
   ],
   "source": [
    "execute(\"create database testdb;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24f2baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'create database testdb;'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain a DB Cursor\n",
    "cursor          = conn.cursor();\n",
    "name_Database   = \"testdb\";\n",
    "\n",
    "# Create table statement\n",
    "sqlCreateDatabase = \"create database \"+name_Database+\";\"\n",
    "\n",
    "# Create a table in PostgreSQL database\n",
    "# cursor.execute(sqlCreateDatabase);\n",
    "sqlCreateDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f90e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
