{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85f384f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.base import Engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "from sqlalchemy.orm import declarative_base, Session, sessionmaker\n",
    "from sqlalchemy import Column, Integer, String, TypeDecorator\n",
    "# from sqlalchemy.types import Column, String, TypeDecorator\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "import pandas as pd\n",
    "\n",
    "class HexByteString(TypeDecorator):\n",
    "    \"\"\"  \n",
    "        Class to store model weights in postgress\n",
    "    \"\"\"\n",
    "\n",
    "    impl = String\n",
    "\n",
    "    def process_bind_param(self, value, dialect):\n",
    "        if not isinstance(value, bytes):\n",
    "            raise TypeError(\"HexByteString columns support only bytes values.\")\n",
    "        return value.hex()\n",
    "\n",
    "    def process_result_value(self, value, dialect):\n",
    "        return bytes.fromhex(value) if value else None\n",
    "\n",
    "\n",
    "# Base = declarative_base()\n",
    "# class MyModel(Base):\n",
    "#     data = Column(HexByteString)\n",
    "\n",
    "import json\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4ee7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to db\n",
    "def connec_to_db() -> Engine:\n",
    "    \"\"\"\n",
    "        Connect to postgress database\n",
    "    \"\"\"\n",
    "    #     # ToDo: Add reading variables from linux \n",
    "    #     import os\n",
    "    #     print(os.environ[\"test1\"])\n",
    "    \n",
    "    postgress_url = \"172.19.0.2\"\n",
    "    postgress_password = \"password\"\n",
    "    postgress_user = \"postgres\"\n",
    "    postgress_db = \"test\"\n",
    "    \n",
    "    engine = create_engine(f'postgresql+psycopg2://{postgress_user}:'+\\\n",
    "                           f'{postgress_password}@{postgress_url}/'+\n",
    "                           f'{postgress_db}'\n",
    "                          )\n",
    "    if not database_exists(engine.url):\n",
    "        create_database(engine.url)\n",
    "\n",
    "    #print(engine.url)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a262bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from io import BytesIO\n",
    "\n",
    "Base = declarative_base()\n",
    "class ModelInstance(Base):\n",
    "    \"\"\"\n",
    "        ORM for model's instances\n",
    "    \"\"\"\n",
    "    __tablename__ = \"model_instance\"\n",
    "\n",
    "    model_name = Column(String, primary_key=True)\n",
    "    model_type = Column(String)\n",
    "    fit_params_json = Column(String)\n",
    "    python_library_path = Column(String)\n",
    "    model_bin = Column(HexByteString)\n",
    "    features  = Column(String)\n",
    "    target_column = Column(String)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"model_name={self.model_name}\\n\" + \\\n",
    "               f\"model_type={self.model_type}\" + \\\n",
    "               f\"fit_params_json={self.fit_params_json}\" + \\\n",
    "               f\"python_library_path={self.python_library_path}\"\n",
    "    \n",
    "    def _get_features(self):\n",
    "        open(\"xyu.txt\", 'w+').write(self.features)\n",
    "        return json.loads(self.features)\n",
    "    \n",
    "    def fit(self, \n",
    "            data: pd.DataFrame, \n",
    "            target_column: str = 'y'\n",
    "           ) -> None:\n",
    "        model_class = self._import_sklearn_model_class()\n",
    "        fit_params = json.loads(self.fit_params_json)\n",
    "        model = model_class(**fit_params)\n",
    "        \n",
    "        self.target_column = target_column\n",
    "\n",
    "        features = list(data.keys())\n",
    "        features.remove(target_column)\n",
    "        self.features = json.dumps(features)\n",
    "        \n",
    "        model.fit(X = data[self._get_features()], \n",
    "                  y = data[self.target_column]\n",
    "                 )\n",
    "        \n",
    "        self.model_bin = ModelInstance._model_to_buff(model)\n",
    "        \n",
    "    def predict(self, data: pd.DataFrame) -> Dict[Any, Any]:\n",
    "        model = self._get_model()\n",
    "        data['predict'] = model.predict(X = data[self._get_features()])\n",
    "        return data['predict'].to_dict()\n",
    "    \n",
    "    def _import_sklearn_model_class(self):\n",
    "        \"\"\"\n",
    "            Интроспекция для загрузки модуля sklearn\n",
    "        \"\"\"\n",
    "        from_str = '.'.join(self.python_library_path.split('.')[:2])\n",
    "        res = __import__(from_str)\n",
    "        res = getattr(res, self.python_library_path.split('.')[1])\n",
    "        res = getattr(res, self.python_library_path.split('.')[2])\n",
    "        return res\n",
    "    \n",
    "    @classmethod\n",
    "    def _model_to_buff(cls, model_python) -> bytes:\n",
    "        buffer = BytesIO()\n",
    "        pickle.dump(model_python, buffer)\n",
    "        buffer.seek(0)\n",
    "        return buffer.read()\n",
    "    \n",
    "    @classmethod\n",
    "    def _buff_to_model(csl, model_bin) -> Any:\n",
    "        model_python = pickle.loads(model_bin)\n",
    "        return model_python\n",
    "\n",
    "    def _get_model(self) -> Any:\n",
    "        return ModelInstance._buff_to_model(self.model_bin)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563e668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Удалить таблицу\n",
    "engine = connec_to_db()\n",
    "ModelInstance.__table__.drop(engine)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c95d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: add checking that model is already exists\n",
    "model_instance = ModelInstance(model_name  = \"test_real90\",\n",
    "                               model_type  = \"RandomForestClassifier\",\n",
    "                               fit_params_json = \"{}\",\n",
    "                               python_library_path = \"sklearn.ensemble.RandomForestClassifier\",\n",
    "#                                model_bin = model_to_buff(model)\n",
    "                              )\n",
    "\n",
    "data = pd.read_csv('fastapi_microservice/datasets/iris/data.csv')\n",
    "model_instance.fit(data = data, target_column = \"y\")\n",
    "session.add(model_instance)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5e334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf xyu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f53ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"0\", \"1\", \"2\", \"3\"]"
     ]
    }
   ],
   "source": [
    "!cat xyu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b1c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = model_instance.get_model()\n",
    "# .predict(data_input=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925eca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 0,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 0,\n",
       " 9: 0,\n",
       " 10: 0,\n",
       " 11: 0,\n",
       " 12: 0,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 0,\n",
       " 16: 0,\n",
       " 17: 0,\n",
       " 18: 0,\n",
       " 19: 0,\n",
       " 20: 0,\n",
       " 21: 0,\n",
       " 22: 0,\n",
       " 23: 0,\n",
       " 24: 0,\n",
       " 25: 0,\n",
       " 26: 0,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0,\n",
       " 30: 0,\n",
       " 31: 0,\n",
       " 32: 0,\n",
       " 33: 0,\n",
       " 34: 0,\n",
       " 35: 0,\n",
       " 36: 0,\n",
       " 37: 0,\n",
       " 38: 0,\n",
       " 39: 0,\n",
       " 40: 0,\n",
       " 41: 0,\n",
       " 42: 0,\n",
       " 43: 0,\n",
       " 44: 0,\n",
       " 45: 0,\n",
       " 46: 0,\n",
       " 47: 0,\n",
       " 48: 0,\n",
       " 49: 0,\n",
       " 50: 1,\n",
       " 51: 1,\n",
       " 52: 1,\n",
       " 53: 1,\n",
       " 54: 1,\n",
       " 55: 1,\n",
       " 56: 1,\n",
       " 57: 1,\n",
       " 58: 1,\n",
       " 59: 1,\n",
       " 60: 1,\n",
       " 61: 1,\n",
       " 62: 1,\n",
       " 63: 1,\n",
       " 64: 1,\n",
       " 65: 1,\n",
       " 66: 1,\n",
       " 67: 1,\n",
       " 68: 1,\n",
       " 69: 1,\n",
       " 70: 1,\n",
       " 71: 1,\n",
       " 72: 1,\n",
       " 73: 1,\n",
       " 74: 1,\n",
       " 75: 1,\n",
       " 76: 1,\n",
       " 77: 1,\n",
       " 78: 1,\n",
       " 79: 1,\n",
       " 80: 1,\n",
       " 81: 1,\n",
       " 82: 1,\n",
       " 83: 1,\n",
       " 84: 1,\n",
       " 85: 1,\n",
       " 86: 1,\n",
       " 87: 1,\n",
       " 88: 1,\n",
       " 89: 1,\n",
       " 90: 1,\n",
       " 91: 1,\n",
       " 92: 1,\n",
       " 93: 1,\n",
       " 94: 1,\n",
       " 95: 1,\n",
       " 96: 1,\n",
       " 97: 1,\n",
       " 98: 1,\n",
       " 99: 1,\n",
       " 100: 2,\n",
       " 101: 2,\n",
       " 102: 2,\n",
       " 103: 2,\n",
       " 104: 2,\n",
       " 105: 2,\n",
       " 106: 2,\n",
       " 107: 2,\n",
       " 108: 2,\n",
       " 109: 2,\n",
       " 110: 2,\n",
       " 111: 2,\n",
       " 112: 2,\n",
       " 113: 2,\n",
       " 114: 2,\n",
       " 115: 2,\n",
       " 116: 2,\n",
       " 117: 2,\n",
       " 118: 2,\n",
       " 119: 2,\n",
       " 120: 2,\n",
       " 121: 2,\n",
       " 122: 2,\n",
       " 123: 2,\n",
       " 124: 2,\n",
       " 125: 2,\n",
       " 126: 2,\n",
       " 127: 2,\n",
       " 128: 2,\n",
       " 129: 2,\n",
       " 130: 2,\n",
       " 131: 2,\n",
       " 132: 2,\n",
       " 133: 2,\n",
       " 134: 2,\n",
       " 135: 2,\n",
       " 136: 2,\n",
       " 137: 2,\n",
       " 138: 2,\n",
       " 139: 2,\n",
       " 140: 2,\n",
       " 141: 2,\n",
       " 142: 2,\n",
       " 143: 2,\n",
       " 144: 2,\n",
       " 145: 2,\n",
       " 146: 2,\n",
       " 147: 2,\n",
       " 148: 2,\n",
       " 149: 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fastapi_microservice/datasets/iris/data.csv')\n",
    "session.query(ModelInstance).get(\"test_real90\").predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b954f8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fastapi_microservice/datasets/iris/data.csv')\n",
    "session.query(ModelInstance).get(\"test_real0\").get_model().predict(data[session.query(ModelInstance).get(\"test_real0\")._get_features()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c948eccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name=test_real90\n",
       "model_type=RandomForestClassifierfit_params_json={}python_library_path=sklearn.ensemble.RandomForestClassifier"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(ModelInstance).all()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e62f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede56086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
