{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43013c79",
   "metadata": {},
   "source": [
    "## ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.base import Engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "from sqlalchemy.orm import declarative_base, Session, sessionmaker\n",
    "from sqlalchemy import Column, Integer, String, TypeDecorator\n",
    "# from sqlalchemy.types import Column, String, TypeDecorator\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "\n",
    "class HexByteString(TypeDecorator):\n",
    "    \"\"\"  \n",
    "        Class to store model weights in postgress\n",
    "    \"\"\"\n",
    "\n",
    "    impl = String\n",
    "\n",
    "    def process_bind_param(self, value, dialect):\n",
    "        if not isinstance(value, bytes):\n",
    "            raise TypeError(\"HexByteString columns support only bytes values.\")\n",
    "        return value.hex()\n",
    "\n",
    "    def process_result_value(self, value, dialect):\n",
    "        return bytes.fromhex(value) if value else None\n",
    "\n",
    "\n",
    "# Base = declarative_base()\n",
    "# class MyModel(Base):\n",
    "#     data = Column(HexByteString)\n",
    "\n",
    "import json\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a562cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to db\n",
    "def connec_to_db() -> Engine:\n",
    "    \"\"\"\n",
    "        Connect to postgress database\n",
    "    \"\"\"\n",
    "    #     # ToDo: Add reading variables from linux \n",
    "    #     import os\n",
    "    #     print(os.environ[\"test1\"])\n",
    "    \n",
    "    postgress_url = \"172.19.0.2\"\n",
    "    postgress_password = \"password\"\n",
    "    postgress_user = \"postgres\"\n",
    "    postgress_db = \"test\"\n",
    "    \n",
    "    engine = create_engine(f'postgresql+psycopg2://{postgress_user}:'+\\\n",
    "                           f'{postgress_password}@{postgress_url}/'+\n",
    "                           f'{postgress_db}'\n",
    "                          )\n",
    "    if not database_exists(engine.url):\n",
    "        create_database(engine.url)\n",
    "\n",
    "    #print(engine.url)\n",
    "    return engine\n",
    "\n",
    "Base = declarative_base()\n",
    "class ModelSignature(Base):\n",
    "    \"\"\"\n",
    "        ORM for model's signatures\n",
    "    \"\"\"\n",
    "    __tablename__ = \"model_signature\"\n",
    "\n",
    "    model_type = Column(String, primary_key=True)\n",
    "    fit_params_json = Column(String)\n",
    "    python_library_path = Column(String)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{model_type=%s, fit_params_json=%s, python_library_path=%s}\"%(self.model_type, \n",
    "                                                      self.fit_params_json, self.python_library_path\n",
    "                                                     )\n",
    "    \n",
    "    def _to_json(self):\n",
    "        return {\"model_type\": self.model_type,\n",
    "                \"fit_params_json\": json.loads(self.fit_params_json),\n",
    "                \"python_library_path\": self.python_library_path\n",
    "               }\n",
    "\n",
    "def load_model_signature_to_db():\n",
    "    engine = connec_to_db()\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    fn_json = \"model_signature.json\"\n",
    "    model_signatures_json = json.load(open(fn_json, 'r'))\n",
    "    for dct in model_signatures_json:\n",
    "        model_type = dct['model_type']\n",
    "        fit_params_json = json.dumps(dct['fit_params_json'])\n",
    "        python_library_path = dct['python_library_path']\n",
    "        model_signature = ModelSignature(model_type = model_type, \n",
    "                                         fit_params_json = fit_params_json,\n",
    "                                         python_library_path = python_library_path\n",
    "                                        )\n",
    "        session.add(model_signature)\n",
    "    \n",
    "    session.commit()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "class WrongModelType(Exception):\n",
    "    pass\n",
    "\n",
    "def get_model_params(model_type: str, session: Session) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "        Get avaliable params for model_type\n",
    "    \"\"\"\n",
    "    row = session.query(ModelSignature).get(model_type)\n",
    "    \n",
    "    if hasattr(row, \"fit_params_json\"):\n",
    "        return json.loads(row.fit_params_json)\n",
    "    else:\n",
    "        raise WrongModelType(f\"There are no model_type={model_type}\")\n",
    "\n",
    "@lru_cache(None)\n",
    "def get_list_model_signatures(session: Session) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "        Get list and all avaliables models types with their fit_params_json\n",
    "    \"\"\"\n",
    "    resp = session.query(ModelSignature).all()\n",
    "    json_shema_list = [line._to_json() for line in resp]\n",
    "    return json_shema_list\n",
    "\n",
    "\n",
    "def _change_json_schema(json_shema_list: List[Dict[str, str]]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "        Change one json format to more usefull    \n",
    "    \"\"\"\n",
    "    return {line['model_type']: line['fit_params_json'] for line in json_shema_list}\n",
    "\n",
    "class WrongModelType(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_model_signature(session: Session, model_type: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "        Get single model_signature\n",
    "    \"\"\"\n",
    "    resp = session.query(ModelSignature).filter_by(model_type=model_type).all()\n",
    "    if len(resp) == 0:\n",
    "        raise WrongModelType(f\"There is no model_type={model_type}\")\n",
    "    elif len(resp) > 1:\n",
    "        raise WrongModelType(f\"There are several model with these model_type={model_type}\")\n",
    "    else:\n",
    "        return resp[0]\n",
    "    \n",
    "class WrongFitParams(Exception):\n",
    "    pass\n",
    "\n",
    "from pydoc import locate\n",
    "def check_fit_params_json(model_signature: ModelSignature,\n",
    "                          input_json: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "        Check that input types are valid\n",
    "    \"\"\"\n",
    "        \n",
    "    json_shema = model_signature._to_json()['fit_params_json']\n",
    "    \n",
    "    for key, value in input_json.items():\n",
    "        if key not in json_shema:\n",
    "            raise WrongFitParams(f\"Unknown params {key}\")\n",
    "\n",
    "        valid_type = json_shema[key]\n",
    "        if not isinstance(value, locate(valid_type)):\n",
    "            raise WrongFitParams(f\"{key} = {value} that is not valid type \" + \\\n",
    "                                 f\"(valid_type is {valid_type}, these type is {str(type(value))}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ececa0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_model_signature(session, \"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eedb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0e088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Удалить таблицу\n",
    "engine = connec_to_db()\n",
    "ModelSignature.__table__.drop(engine)\n",
    "\n",
    "## Записываем все в базу\n",
    "engine = load_model_signature_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a584f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем сессию\n",
    "engine = connec_to_db()\n",
    "    \n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255ba13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем проверку типов\n",
    "input_json = {\"min_samples_leaf\": 1}\n",
    "model_signature = get_model_signature(session = session, \n",
    "                                  model_type = \"RandomForestClassifier\")\n",
    "    \n",
    "check_fit_params_json(model_signature = model_signature,\n",
    "                      input_json = input_json\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6452e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_signature._to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d725e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_signature = get_model_signature(session = session, \n",
    "                                  model_type = \"RandomForestClassifier\")\n",
    "    \n",
    "check_fit_params_json(model_signature = model_signature,\n",
    "                      input_json = {}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61df646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# elif len(resp)\n",
    "# resp._to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640309bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.query(ModelSignature).filter_by(model_type=\"RandomForestClassifier\").first()._to_json()['python_library_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3addbad4",
   "metadata": {},
   "source": [
    "### FastApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6d3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exceptions.py\n",
    "class WrongInputData(Exception):\n",
    "    \"\"\"\n",
    "        Error at input_data_json\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# utils.py\n",
    "def __json_to_dataframe(json_input):\n",
    "    \"\"\"\n",
    "        Change input json to \n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_json(json_input)\n",
    "        #ToDo: Check that types are not objects or string\n",
    "        # These will cause error with hight probability\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise WrongInputData(e)\n",
    "\n",
    "def import_sklearn_model_class(python_library_path):\n",
    "    \"\"\"\n",
    "        Интроспекция для загрузки модуля sklearn\n",
    "    \"\"\"\n",
    "    from_str = '.'.join(python_library_path.split('.')[:2])\n",
    "    res = __import__(from_str)\n",
    "    res = getattr(res, python_library_path.split('.')[1])\n",
    "    res = getattr(res, python_library_path.split('.')[2])\n",
    "    return res\n",
    "\n",
    "import pandas as pd\n",
    "def fit_model(model_name: str, \n",
    "              model_type: str,\n",
    "              fit_params_json: str, \n",
    "              input_data_json: str,\n",
    "              target_column: str = \"y\",\n",
    "              session: Session = session\n",
    "             ) -> None:\n",
    "    \"\"\"\n",
    "        fit model\n",
    "    \"\"\"\n",
    "    data  = __json_to_dataframe(input_data_json)\n",
    "    if not target_column in data:\n",
    "        raise WrongInputData(f'There are no \"{target_column}\" at input_data_json')\n",
    "    \n",
    "    model_signature = get_model_signature(session = session, \n",
    "                                      model_type = model_type\n",
    "                                     )\n",
    "    python_library_path   = model_signature.python_library_path\n",
    "\n",
    "    check_fit_params_json(model_signature = model_signature,\n",
    "                          input_json = fit_params_json\n",
    "                         )\n",
    "    \n",
    "#     print(python_library_path)\n",
    "#     print(import_sklearn_model_class(python_library_path))\n",
    "    model_class = import_sklearn_model_class(python_library_path)\n",
    "    model = model_class(**fit_params_json)\n",
    "    \n",
    "    features = list(data.keys())\n",
    "    features.remove(target_column)\n",
    "\n",
    "    model.fit(X = data[features], \n",
    "              y = data[target_column]\n",
    "             )\n",
    "    \n",
    "    return model\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e972bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем создание модели\n",
    "# ToDO: Переписать сигнатуры\n",
    "model = fit_model(model_name = \"test123\",\n",
    "          model_type = \"RandomForestClassifier\",\n",
    "          fit_params_json = {},\n",
    "          input_data_json = pd.read_csv(\"fastapi_microservice/datasets/iris/data.csv\").to_json()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71342bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_class(n_estimators=0.0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2342698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type\n",
    "# model_library\n",
    "# model_bin\n",
    "# model_\n",
    "\n",
    "# model_type = \"\"\n",
    "# model_name\n",
    "# fit_params_json\n",
    "# python_library_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e296312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from io import BytesIO\n",
    "\n",
    "Base = declarative_base()\n",
    "class ModelInstance(Base):\n",
    "    \"\"\"\n",
    "        ORM for model's instances\n",
    "    \"\"\"\n",
    "    __tablename__ = \"model_instance\"\n",
    "\n",
    "    model_name = Column(String, primary_key=True)\n",
    "    model_type = Column(String)\n",
    "    fit_params_json = Column(String)\n",
    "    python_library_path = Column(String)\n",
    "    model_bin = Column(HexByteString)\n",
    "    features  = Column(String)\n",
    "    target_column = Column(String)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"model_name={self.model_name}\\n\" + \\\n",
    "               f\"model_type={self.model_type}\" + \\\n",
    "               f\"fit_params_json={self.fit_params_json}\" + \\\n",
    "               f\"python_library_path={self.python_library_path}\"\n",
    "    \n",
    "    def _get_features(self):\n",
    "        return json.loads(self.features)\n",
    "    \n",
    "    def fit(self, \n",
    "            data: pd.DataFrame, \n",
    "            target_column: str = 'y'\n",
    "           ) -> None:\n",
    "        model_class = self._import_sklearn_model_class()\n",
    "        fit_params = json.loads(self.fit_params_json)\n",
    "        model = model_class(**fit_params)\n",
    "\n",
    "        self.features = list(data.keys())\n",
    "        self.features.remove(target_column)\n",
    "        self.features = json.dumps(self.features)\n",
    "        self.target_column = target_column\n",
    "        \n",
    "        model.fit(X = data[self._get_features()], \n",
    "                  y = data[self.target_column]\n",
    "                 )\n",
    "        \n",
    "        self.model_bin = ModelInstance._model_to_buff(model)\n",
    "        \n",
    "    def predict(self, data: pd.DataFrame) -> Dict[Any, Any]:\n",
    "        model = ModelInstance._buff_to_model(model.bin)\n",
    "#         print(self._get_features())\n",
    "#         data['predict'] = model.predict(X = data[self._get_features()])\n",
    "#         return data['predict'].to_dict()\n",
    "    \n",
    "    def _import_sklearn_model_class(self):\n",
    "        \"\"\"\n",
    "            Интроспекция для загрузки модуля sklearn\n",
    "        \"\"\"\n",
    "        from_str = '.'.join(self.python_library_path.split('.')[:2])\n",
    "        res = __import__(from_str)\n",
    "        res = getattr(res, self.python_library_path.split('.')[1])\n",
    "        res = getattr(res, self.python_library_path.split('.')[2])\n",
    "        return res\n",
    "    \n",
    "    @classmethod\n",
    "    def _model_to_buff(cls, model_python) -> bytes:\n",
    "        buffer = BytesIO()\n",
    "        pickle.dump(model_python, buffer)\n",
    "        buffer.seek(0)\n",
    "        return buffer.read()\n",
    "    \n",
    "    @classmethod\n",
    "    def _buff_to_model(csl, model_bin) -> Any:\n",
    "        model_python = pickle.loads(model_bin)\n",
    "        return model_python\n",
    "\n",
    "    def get_model(self) -> Any:\n",
    "        return ModelInstance._buff_to_model(self.model_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Удалить таблицу\n",
    "engine = connec_to_db()\n",
    "ModelInstance.__table__.drop(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c75852",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "962e6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c017745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = ModelInstance(model_name  = \"test_real\",\n",
    "                               model_type  = \"RandomForestClassifier\",\n",
    "                               fit_params_json = \"{}\",\n",
    "                               python_library_path = \"sklearn.ensemble.RandomForestClassifier\",\n",
    "#                                model_bin = model_to_buff(model)\n",
    "                              )\n",
    "\n",
    "data = pd.read_csv('fastapi_microservice/datasets/iris/data.csv')\n",
    "model_instance.fit(data = data, target_column = \"y\")\n",
    "session.add(model_instance)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c32eb919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- y\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5 features, but RandomForestClassifier is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5103/1707264078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# o = session.query(ModelInstance).get(\"test_real\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelInstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# predict(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     data[o._get_features()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5 features, but RandomForestClassifier is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "# o = session.query(ModelInstance).get(\"test_real\")\n",
    "session.query(ModelInstance).get(\"test_real\").get_model().predict(data)\n",
    "# predict(\n",
    "#     data[o._get_features()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1adf5f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- y\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5 features, but RandomForestClassifier is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5055/3682774907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelInstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_real0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5 features, but RandomForestClassifier is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "session.query(ModelInstance).get(\"test_real0\").get_model().predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4994297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"fastapi_microservice/datasets/iris/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50b3d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['p'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "627afe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0746af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from io import BytesIO\n",
    "# def model_to_buff(model_python):\n",
    "#     buffer = BytesIO()\n",
    "#     pickle.dump(model_python, buffer)\n",
    "#     buffer.seek(0)\n",
    "#     return buffer.read()\n",
    "\n",
    "# def buff_to_model(model_bin):\n",
    "#     model_python = pickle.loads(model_bin)\n",
    "#     return model_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "860faa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = ModelInstance(model_name  = \"test\",\n",
    "              model_type  = \"test\",\n",
    "              fit_params_json = \"test\",\n",
    "              python_library_path = \"test\",\n",
    "              model_bin = model_to_buff(model)\n",
    "             )\n",
    "\n",
    "session.add(model_instance)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "401b203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fastapi_microservice/datasets/iris/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79a85262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sklearn.ensemble.RandomForestClassifier'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_instance.python_library_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57cb6cfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\"0\", \"1\", \"2\", \"3\"]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[\"0\", \"1\", \"2\", \"3\"]'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5028/77868125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fastapi_microservice/datasets/iris/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# session.add(model_instance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# session.commit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5028/893246307.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, target_column)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         model.fit(X = data[self.features], \n\u001b[0m\u001b[1;32m     39\u001b[0m                   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                  )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[\"0\", \"1\", \"2\", \"3\"]'"
     ]
    }
   ],
   "source": [
    "model_instance = ModelInstance(model_name  = \"test_real\",\n",
    "                               model_type  = \"RandomForestClassifier\",\n",
    "                               fit_params_json = \"{}\",\n",
    "                               python_library_path = \"sklearn.ensemble.RandomForestClassifier\",\n",
    "#                                model_bin = model_to_buff(model)\n",
    "                              )\n",
    "\n",
    "data = pd.read_csv('fastapi_microservice/datasets/iris/data.csv')\n",
    "model_instance.fit(data = data, target_column = \"y\")\n",
    "# session.add(model_instance)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e599676",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5199/4034625774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelInstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "session.query(ModelInstance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "76149d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(ModelInstance).get(\"test\").get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6951213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buff_to_model(session.query(ModelInstance).get(\"test\").model_bin).predict(pd.read_csv(\"fastapi_microservice/datasets/iris/data.csv\").drop(\"y\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "157cb84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "345e0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buff_to_model(model_to_buff(model)).estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bin = get_model_bin(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1be259d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(model_bin.read()).predict(pd.read_csv(\"fastapi_microservice/datasets/iris/data.csv\").drop(\"y\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de229c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d74d9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bin = get_model_bin(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c72642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BytesIO at 0x7f3bc4192090>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ac6491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name=test\n",
       "model_type=testfit_params_json=testpython_library_path=test"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a24540ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2316e287",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5004/1536949142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_estimators'"
     ]
    }
   ],
   "source": [
    "model.fit(data, data['y'], n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5958faac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5004/1730150778.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fit_model(model_name = \"test123\",\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RandomForestClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mfit_params_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0minput_data_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fastapi_microservice/datasets/iris/data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          )\n",
      "\u001b[0;32m/tmp/ipykernel_5004/485083138.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model_name, model_type, fit_params_json, input_data_json, target_column, session)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     model.fit(X = data[features], \n\u001b[0m\u001b[1;32m     63\u001b[0m               \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m               \u001b[0;34m**\u001b[0m\u001b[0mfit_params_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_estimators'"
     ]
    }
   ],
   "source": [
    "fit_model(model_name = \"test123\",\n",
    "          model_type = \"RandomForestClassifier\",\n",
    "          fit_params_json = {},\n",
    "          input_data_json = pd.read_csv(\"fastapi_microservice/datasets/iris/data.csv\").to_json()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7202dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fastapi_microservice/datasets/iris/data.csv\")\n",
    "# rename(columns = {\"y\": \"target\"})\n",
    "# to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d41cf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  y\n",
       "0    5.1  3.5  1.4  0.2  0\n",
       "1    4.9  3.0  1.4  0.2  0\n",
       "2    4.7  3.2  1.3  0.2  0\n",
       "3    4.6  3.1  1.5  0.2  0\n",
       "4    5.0  3.6  1.4  0.2  0\n",
       "..   ...  ...  ...  ... ..\n",
       "145  6.7  3.0  5.2  2.3  2\n",
       "146  6.3  2.5  5.0  1.9  2\n",
       "147  6.5  3.0  5.2  2.0  2\n",
       "148  6.2  3.4  5.4  2.3  2\n",
       "149  5.9  3.0  5.1  1.8  2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906abd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 'int',\n",
       " 'max_depth': 'int',\n",
       " 'random_state': 'int',\n",
       " 'min_samples_leaf': 'int',\n",
       " 'learning_rate': 'int'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_signature(session = session, \n",
    "                                     model_type = \"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287cdc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'RandomForestClassifier',\n",
       "  'fit_params_json': {'n_estimators': 'int',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int',\n",
       "   'learning_rate': 'int'},\n",
       "  'python_library_path': 'sklearn.ensemble.RandomForestClassifier'},\n",
       " {'model_type': 'LogisticRegression',\n",
       "  'fit_params_json': {'n_estimators': 'int',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int',\n",
       "   'learning_rate': 'int'},\n",
       "  'python_library_path': 'sklearn.linear_model.LogisticRegression'},\n",
       " {'model_type': 'GradientBoostingClassifier',\n",
       "  'fit_params_json': {'penalty': 'str',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int'},\n",
       "  'python_library_path': 'sklearn.ensemble.GradientBoostingClassifier'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_list_model_signatures(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2536d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sklearn_model_class(session, model_type):\n",
    "    \"\"\"\n",
    "        Интроспекция для загрузки модуля sklearn\n",
    "    \"\"\"\n",
    "    from_str = '.'.join(model_type.split('.')[:2])\n",
    "    res = __import__(from_str)\n",
    "    res = getattr(res, model_type.split('.')[1])\n",
    "    res = getattr(res, model_type.split('.')[2])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5723a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = import_sklearn_model_class(\"sklearn.ensemble.RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb856480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33111c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(input_json['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9762c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fabedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_shema = get_model_signatures(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b34c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\"learning_rate\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "074b3b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'RandomForestClassifier',\n",
       "  'fit_params_json': {'n_estimators': 'int',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int',\n",
       "   'learning_rate': 'float'}},\n",
       " {'model_type': 'LogisticRegression',\n",
       "  'fit_params_json': {'n_estimators': 'int',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int',\n",
       "   'learning_rate': 'float'}},\n",
       " {'model_type': 'GradientBoostingClassifier',\n",
       "  'fit_params_json': {'penalty': 'str',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int'}}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_shema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "895def89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_shema[0]['fit_params_json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a06f01a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': {'n_estimators': 'int',\n",
       "  'max_depth': 'int',\n",
       "  'random_state': 'int',\n",
       "  'min_samples_leaf': 'int',\n",
       "  'learning_rate': 'float'},\n",
       " 'LogisticRegression': {'n_estimators': 'int',\n",
       "  'max_depth': 'int',\n",
       "  'random_state': 'int',\n",
       "  'min_samples_leaf': 'int',\n",
       "  'learning_rate': 'float'},\n",
       " 'GradientBoostingClassifier': {'penalty': 'str',\n",
       "  'max_depth': 'int',\n",
       "  'random_state': 'int',\n",
       "  'min_samples_leaf': 'int'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    " res = {}\n",
    "    for line in resp:\n",
    "        dct = line._to_json()\n",
    "        res[dct['model_type']] = dct['fit_params_json']\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2186416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4940/2121237831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m check_fit_params_json(json_shema = json_shema['RandomForestClassifier'],\n\u001b[0m\u001b[1;32m     19\u001b[0m                       \u001b[0minput_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                      )\n",
      "\u001b[0;32m/tmp/ipykernel_4940/2121237831.py\u001b[0m in \u001b[0;36mcheck_fit_params_json\u001b[0;34m(json_shema, input_json)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mWrongFitParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown params {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_shema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mvalid_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_shema\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mWrongFitParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{key} = {value} that is not valid type {valid_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "class WrongFitParams(Exception):\n",
    "    pass\n",
    "\n",
    "from pydoc import locate\n",
    "def check_fit_params_json(session: Session,\n",
    "                          model_type: str, \n",
    "                          input_json: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "        Check that input types are valid\n",
    "    \"\"\"\n",
    "    \n",
    "    all_json_shema = get_model_signatures(session)\n",
    "    \n",
    "    for key, value in input_json.items():\n",
    "        if key not in json_shema:\n",
    "            raise WrongFitParams(f\"Unknown params {key}\")\n",
    "\n",
    "        valid_type = json_shema[key]\n",
    "        if not isinstance(value, locate(valid_type)):\n",
    "            raise WrongFitParams(f\"{key} = {value} that is not valid type {valid_type}\")\n",
    "    return\n",
    "\n",
    "check_fit_params_json(json_shema = json_shema['RandomForestClassifier'],\n",
    "                      input_json = input_json\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e312b2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4940/1882676314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_shema\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RandomForestClassifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "json_shema['RandomForestClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e4d19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 'int',\n",
       " 'max_depth': 'int',\n",
       " 'random_state': 'int',\n",
       " 'min_samples_leaf': 'int',\n",
       " 'learning_rate': 'float'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_params(\"RandomForestClassifier\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7311530",
   "metadata": {},
   "outputs": [
    {
     "ename": "WrongModelType",
     "evalue": "There are no model_type=RandomForestClassifier097",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWrongModelType\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4940/1417776178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_model_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RandomForestClassifier097\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4940/4123918599.py\u001b[0m in \u001b[0;36mget_model_params\u001b[0;34m(model_type, session)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mWrongModelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There are no model_type={model_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWrongModelType\u001b[0m: There are no model_type=RandomForestClassifier097"
     ]
    }
   ],
   "source": [
    "get_model_params(\"RandomForestClassifier097\", session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cdd8c1",
   "metadata": {},
   "source": [
    "#### PyTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442bc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"class\")\n",
    "def db_class(request):\n",
    "    class DummyDB:\n",
    "        pass\n",
    "\n",
    "    # set a class attribute on the invoking test context\n",
    "    request.cls.db = DummyDB()\n",
    "    \n",
    "# content of test_unittest_db.py\n",
    "\n",
    "import unittest\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.mark.usefixtures(\"db_class\")\n",
    "class MyTest(unittest.TestCase):\n",
    "    def test_method1(self):\n",
    "        assert hasattr(self, \"db\")\n",
    "        assert 0, self.db  # fail for demo purposes\n",
    "\n",
    "    def test_method2(self):\n",
    "        assert 0, self.db  # fail for demo purposes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25967ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelSignature.__table__.drop(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7544731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:password@172.19.0.2/test\n"
     ]
    }
   ],
   "source": [
    "engine = connec_to_db()\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3d3a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_signature_to_db():\n",
    "    engine = connec_to_db()\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    fn_json = \"model_signature.json\"\n",
    "    model_signatures_json = json.load(open(fn_json, 'r'))\n",
    "    for dct in model_signatures_json:\n",
    "        model_type = dct['model_type']\n",
    "        fit_params_json = json.dumps(dct['fit_params_json'])\n",
    "        model_signature = ModelSignature(model_type = model_type, \n",
    "                                         fit_params_json = fit_params_json\n",
    "                                        )\n",
    "        session.add(model_signature)\n",
    "    \n",
    "    session.commit()\n",
    "    res = session.query(ModelSignature).filter_by(model_type=\"RandomForestClassifier\").first()\n",
    "    return res\n",
    "#     session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49d04f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:password@172.19.0.2/test\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"ModelSignature_pkey\"\nDETAIL:  Key (model_type)=(RandomForestClassifier) already exists.\n\n[SQL: INSERT INTO \"ModelSignature\" (model_type, fit_params_json) VALUES (%(model_type)s, %(fit_params_json)s)]\n[parameters: ({'model_type': 'RandomForestClassifier', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'LogisticRegression', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'GradientBoostingClassifier', 'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'})]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m                     self.dialect.do_executemany(\n\u001b[0m\u001b[1;32m   1800\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mxtras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg2_extras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             context._psycopg2_fetched_rows = xtras.execute_values(\n\u001b[0m\u001b[1;32m    954\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"ModelSignature_pkey\"\nDETAIL:  Key (model_type)=(RandomForestClassifier) already exists.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4892/243827472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelSignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RandomForestClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0msa_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No transaction is begun.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self, _to_root)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPREPARED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_prepare_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 raise exc.FlushError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flushing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3383\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3384\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flushing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3521\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3522\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3523\u001b[0;31m                 \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_capture_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3525\u001b[0m     def bulk_save_objects(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 compat.raise_(\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_on_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3482\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3483\u001b[0;31m                 \u001b[0mflush_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3484\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_on_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopological\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostsort_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinalize_flush_changes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, uow)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sqlalchemy.orm.persistence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         util.preloaded.orm_persistence.save_obj(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0muow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates_for_mapper_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py\u001b[0m in \u001b[0;36msave_obj\u001b[0;34m(base_mapper, states, uowtransaction, single)\u001b[0m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         _emit_insert_statements(\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mbase_mapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0muowtransaction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py\u001b[0m in \u001b[0;36m_emit_insert_statements\u001b[0;34m(base_mapper, uowtransaction, mapper, table, insert, bookkeeping)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mmultiparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             c = connection._execute_20(\n\u001b[0m\u001b[1;32m   1098\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_20\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1629\u001b[0m             )\n\u001b[1;32m   1630\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_10style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_10style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def exec_driver_sql(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    330\u001b[0m     ):\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_force\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             return connection._execute_clauseelement(\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mlinting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler_linting\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN_LINTING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         )\n\u001b[0;32m-> 1498\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1499\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_compiled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1863\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   2044\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m                     self.dialect.do_executemany(\n\u001b[0m\u001b[1;32m   1800\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m                     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    951\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mxtras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg2_extras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             context._psycopg2_fetched_rows = xtras.execute_values(\n\u001b[0m\u001b[1;32m    954\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"ModelSignature_pkey\"\nDETAIL:  Key (model_type)=(RandomForestClassifier) already exists.\n\n[SQL: INSERT INTO \"ModelSignature\" (model_type, fit_params_json) VALUES (%(model_type)s, %(fit_params_json)s)]\n[parameters: ({'model_type': 'RandomForestClassifier', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'LogisticRegression', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'GradientBoostingClassifier', 'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'})]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)"
     ]
    }
   ],
   "source": [
    "    engine = connec_to_db()\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    fn_json = \"model_signature.json\"\n",
    "    model_signatures_json = json.load(open(fn_json, 'r'))\n",
    "    for dct in model_signatures_json:\n",
    "        model_type = dct['model_type']\n",
    "        fit_params_json = json.dumps(dct['fit_params_json'])\n",
    "        model_signature = ModelSignature(model_type = model_type, \n",
    "                                         fit_params_json = fit_params_json\n",
    "                                        )\n",
    "        session.add(model_signature)\n",
    "    \n",
    "    session.commit()\n",
    "    res = session.query(ModelSignature).filter_by(model_type=\"RandomForestClassifier\").first()\n",
    "    res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54d04de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:password@172.19.0.2/test\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"ModelSignature_pkey\"\nDETAIL:  Key (model_type)=(RandomForestClassifier) already exists.\n\n[SQL: INSERT INTO \"ModelSignature\" (model_type, fit_params_json) VALUES (%(model_type)s, %(fit_params_json)s)]\n[parameters: ({'model_type': 'RandomForestClassifier', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'LogisticRegression', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'GradientBoostingClassifier', 'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'})]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m                     self.dialect.do_executemany(\n\u001b[0m\u001b[1;32m   1800\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mxtras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg2_extras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             context._psycopg2_fetched_rows = xtras.execute_values(\n\u001b[0m\u001b[1;32m    954\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"ModelSignature_pkey\"\nDETAIL:  Key (model_type)=(RandomForestClassifier) already exists.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4892/3277527873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_model_signature_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4892/1510777010.py\u001b[0m in \u001b[0;36mload_model_signature_to_db\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelSignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RandomForestClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0msa_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No transaction is begun.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self, _to_root)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPREPARED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_prepare_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 raise exc.FlushError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flushing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3383\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3384\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flushing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3521\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3522\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3523\u001b[0;31m                 \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_capture_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3525\u001b[0m     def bulk_save_objects(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 compat.raise_(\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_on_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3482\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3483\u001b[0;31m                 \u001b[0mflush_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3484\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_on_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopological\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostsort_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinalize_flush_changes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, uow)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sqlalchemy.orm.persistence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         util.preloaded.orm_persistence.save_obj(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0muow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates_for_mapper_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py\u001b[0m in \u001b[0;36msave_obj\u001b[0;34m(base_mapper, states, uowtransaction, single)\u001b[0m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         _emit_insert_statements(\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mbase_mapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0muowtransaction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py\u001b[0m in \u001b[0;36m_emit_insert_statements\u001b[0;34m(base_mapper, uowtransaction, mapper, table, insert, bookkeeping)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mmultiparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             c = connection._execute_20(\n\u001b[0m\u001b[1;32m   1098\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_20\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1629\u001b[0m             )\n\u001b[1;32m   1630\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_10style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_10style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def exec_driver_sql(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    330\u001b[0m     ):\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_force\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             return connection._execute_clauseelement(\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mlinting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler_linting\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN_LINTING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         )\n\u001b[0;32m-> 1498\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1499\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_compiled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1863\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   2044\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m                     self.dialect.do_executemany(\n\u001b[0m\u001b[1;32m   1800\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m                     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    951\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mxtras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg2_extras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             context._psycopg2_fetched_rows = xtras.execute_values(\n\u001b[0m\u001b[1;32m    954\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"ModelSignature_pkey\"\nDETAIL:  Key (model_type)=(RandomForestClassifier) already exists.\n\n[SQL: INSERT INTO \"ModelSignature\" (model_type, fit_params_json) VALUES (%(model_type)s, %(fit_params_json)s)]\n[parameters: ({'model_type': 'RandomForestClassifier', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'LogisticRegression', 'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'}, {'model_type': 'GradientBoostingClassifier', 'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'})]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)"
     ]
    }
   ],
   "source": [
    "load_model_signature_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cf1e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:password@172.19.0.2/test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{model_type=RandomForestClassifier, fit_params_json={\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = connec_to_db()\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "res = session.query(ModelSignature).filter_by(model_type=\"RandomForestClassifier\").first()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95a34f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(session)\n",
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "081d51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "from functools import lru_cache\n",
    "\n",
    "class WrongModelType(Exception):\n",
    "    pass\n",
    "\n",
    "def get_model_params(model_type: str, session: Session) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "        Get avaliable params for model_type\n",
    "    \"\"\"\n",
    "    row = session.query(ModelSignature).get(model_type)\n",
    "    \n",
    "    if hasattr(row, \"fit_params_json\"):\n",
    "        return json.loads(fit_params_json)\n",
    "    else:\n",
    "        raise WrongModelType(f\"There are no model_type={model_type}\")\n",
    "\n",
    "@lru_cache(None)\n",
    "def get_model_signatures(session: Session) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "        Get list and all avaliables models params\n",
    "    \"\"\"\n",
    "    resp = session.query(ModelSignature).all()\n",
    "    return [line._to_json() for line in resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e397325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'str',\n",
       " 'max_depth': 'int',\n",
       " 'random_state': 'int',\n",
       " 'min_samples_leaf': 'int'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_params(\"RandomForestClassifier\", session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d740047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{model_type=RandomForestClassifier, fit_params_json={\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(ModelSignature).all()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2eafb60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'RandomForestClassifier',\n",
       "  'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'},\n",
       " {'model_type': 'LogisticRegression',\n",
       "  'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'},\n",
       " {'model_type': 'GradientBoostingClassifier',\n",
       "  'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_signatures(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69c1397a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_sa_instance_state',\n",
       " 'model_type',\n",
       " 'fit_params_json',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__tablename__',\n",
       " '__repr__',\n",
       " '_sa_class_manager',\n",
       " '__table__',\n",
       " '__init__',\n",
       " '__mapper__',\n",
       " 'registry',\n",
       " 'metadata',\n",
       " '__abstract__',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '_sa_registry',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(ModelSignature).get(\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65690bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5af3d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " our_user = (session.query(ModelSignature).filter_by(model_type=\"ed\").first()) \n",
    "our_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.query(ModelSignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5683f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<User(model_type='ed', fit_params_json='Ed Jones')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "model_signature = ModelSignature(model_type=\"ed\", fit_params_json=\"Ed Jones\")\n",
    "session.add(model_signature)\n",
    "\n",
    "our_user = (session.query(ModelSignature).filter_by(model_type=\"ed\").first()) \n",
    "our_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09105338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import json\n",
    "possible_models = [{\"model_type\": \"RandomForestClassifier\",\n",
    "                    \"fit_params_json\": {\"n_estimators\": \"int\",\n",
    "                                        \"max_depth\": \"int\",\n",
    "                                        \"random_state\": \"int\",\n",
    "                                        \"min_samples_leaf\": \"int\",\n",
    "                                        \"learning_rate\": \"float\"\n",
    "                                       }\n",
    "                   },\n",
    "                   {\"model_type\": \"LogisticRegression\",\n",
    "                    \"fit_params_json\": {\"n_estimators\": \"int\",\n",
    "                                        \"max_depth\": \"int\",\n",
    "                                        \"random_state\": \"int\",\n",
    "                                        \"min_samples_leaf\": \"int\",\n",
    "                                        \"learning_rate\": \"float\"\n",
    "                                       }\n",
    "                   },\n",
    "                   {\"model_type\": \"GradientBoostingClassifier\",\n",
    "                   \"fit_params_json\": {\"penalty\": \"str\",\n",
    "                                       \"max_depth\": \"int\",\n",
    "                                       \"random_state\": \"int\",\n",
    "                                       \"min_samples_leaf\": \"int\"\n",
    "                                       }\n",
    "                   }\n",
    "                  ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b26f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(possible_models, \n",
    "          open(\"model_signature.json\", 'w+'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76323188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'RandomForestClassifier',\n",
       "  'fit_params_json': {'n_estimators': 'int',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int',\n",
       "   'learning_rate': 'float'}},\n",
       " {'model_type': 'LogisticRegression',\n",
       "  'fit_params_json': {'n_estimators': 'int',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int',\n",
       "   'learning_rate': 'float'}},\n",
       " {'model_type': 'GradientBoostingClassifier',\n",
       "  'fit_params_json': {'penalty': 'str',\n",
       "   'max_depth': 'int',\n",
       "   'random_state': 'int',\n",
       "   'min_samples_leaf': 'int'}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open(\"model_signature.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61e0372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'RandomForestClassifier',\n",
       "  'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'},\n",
       " {'model_type': 'LogisticRegression',\n",
       "  'fit_params_json': '{\"n_estimators\": \"int\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\", \"learning_rate\": \"float\"}'},\n",
       " {'model_type': 'GradientBoostingClassifier',\n",
       "  'fit_params_json': '{\"penalty\": \"str\", \"max_depth\": \"int\", \"random_state\": \"int\", \"min_samples_leaf\": \"int\"}'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open(\"model_signature.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b3efce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:password@172.19.0.2/test\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6fc7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlalchemy.engine.base.Engine"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c77cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
